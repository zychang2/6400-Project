{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# import pykakasi\n",
    "import pprint\n",
    "# import cutlet\n",
    "import requests\n",
    "# from backoff import on_exception, expo\n",
    "from requests.exceptions import HTTPError\n",
    "import time\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsF = open('processed_stations_shrinked.json')\n",
    "stations = json.load(stationsF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefectureF = open('open-data-jp-prefectures-master/prefectures.json')\n",
    "prefectures = json.load(prefectureF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': 'Hokkaido', '02': 'Aomori', '03': 'Iwate', '04': 'Miyagi', '05': 'Akita', '06': 'Yamagata', '07': 'Fukushima', '08': 'Ibaraki', '09': 'Tochigi', '10': 'Gunma', '11': 'Saitama', '12': 'Chiba', '13': 'Tokyo', '14': 'Kanagawa', '15': 'Niigata', '16': 'Toyama', '17': 'Ishikawa', '18': 'Fukui', '19': 'Yamanashi', '20': 'Nagano', '21': 'Gifu', '22': 'Shizuoka', '23': 'Aichi', '24': 'Mie', '25': 'Shiga', '26': 'Kyoto', '27': 'Osaka', '28': 'Hyōgo', '29': 'Nara', '30': 'Wakayama', '31': 'Tottori', '32': 'Shimane', '33': 'Okayama', '34': 'Hiroshima', '35': 'Yamaguchi', '36': 'Tokushima', '37': 'Kagawa', '38': 'Ehime', '39': 'Kōchi', '40': 'Fukuoka', '41': 'Saga', '42': 'Nagasaki', '43': 'Kumamoto', '44': 'Ōita', '45': 'Miyazaki', '46': 'Kagoshima', '47': 'Okinawa'}\n"
     ]
    }
   ],
   "source": [
    "prefecture_dict = {}\n",
    "\n",
    "for prefecture in prefectures:\n",
    "    iso_code = prefecture[\"iso\"]\n",
    "    # Split romaji and exclude the last word if more than one word\n",
    "    romaji_parts = prefecture[\"prefecture_romaji\"].split()\n",
    "    if len(romaji_parts) > 1:\n",
    "        romaji_name = \" \".join(romaji_parts[:-1])\n",
    "    else:\n",
    "        romaji_name = romaji_parts[0]  # For single-word cases like \"Hokkaido\"\n",
    "    \n",
    "    # Store in dictionary\n",
    "    prefecture_dict[iso_code] = romaji_name\n",
    "\n",
    "# Output the result\n",
    "print(prefecture_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "eki = \"駅\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '猪名寺'\n",
    "# text = '梅田站'\n",
    "# text = '中山寺駅'\n",
    "# text = '新大阪'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @on_exception(expo, HTTPError, max_tries=5, factor=2)\n",
    "def fetch_wikidata(place_name: str, use_eki=True):\n",
    "    url = 'https://www.wikidata.org/w/api.php'\n",
    "    station_name = place_name if place_name.endswith(eki) else place_name + eki\n",
    "    params = {\n",
    "        'action': 'wbsearchentities',\n",
    "        'format': 'json',\n",
    "        'search': station_name,\n",
    "        'language': 'ja'\n",
    "    }\n",
    "    try:\n",
    "        response = requests.get(url, params=params)\n",
    "        response.raise_for_status()  # Ensure we catch HTTP errors\n",
    "        return response.json()\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None\n",
    "\n",
    "def get_romaji_name(place_name, prefecture_id):\n",
    "    prefecture_name = prefecture_dict.get(prefecture_id, None)\n",
    "    if prefecture_name is None:\n",
    "        print(f\"Invalid prefecture_id: {prefecture_id}\")\n",
    "        return None, None\n",
    "\n",
    "    # Fetch data from Wikidata\n",
    "    data = fetch_wikidata(place_name)\n",
    "    if data is None or 'search' not in data:\n",
    "        print(f\"{place_name} cannot be found on Wikidata\")\n",
    "        return None, None\n",
    "\n",
    "    for item in data['search']:\n",
    "        # Check for an English label in 'display'\n",
    "        if 'display' in item and 'label' in item['display']:\n",
    "            label = item['display']['label']\n",
    "            if label['language'] == 'en':\n",
    "                # Extract the English name and remove \"Station\" if present\n",
    "                romaji_name = label['value'].replace(\"Station\", \"\").strip()\n",
    "\n",
    "                # Extract serving city\n",
    "                if 'description' in item['display'] and 'value' in item['display']['description']:\n",
    "                    description = item['display']['description']['value']\n",
    "                    # print(description)\n",
    "                    if fuzz.partial_ratio(prefecture_name, description) >= 75:\n",
    "                        if prefecture_name == \"Tokyo\":\n",
    "                            city_name = prefecture_name\n",
    "                            return romaji_name, city_name\n",
    "                        location_parts = description.split(',')\n",
    "                        if len(location_parts) >= 2:\n",
    "                            # Follow the rules based on segment count\n",
    "                            if len(location_parts) == 2 or len(location_parts) == 3:\n",
    "                                # If there are 2 or 3 segments, city is the first part\n",
    "                                city_name = location_parts[0].strip().split()[-1]\n",
    "                            elif len(location_parts) == 4:\n",
    "                                # If there are 4 segments, city is the second part\n",
    "                                if \"district\" in location_parts[1]:\n",
    "                                    city_name = location_parts[0].strip().split()[-1]\n",
    "                                else:\n",
    "                                    city_name = location_parts[1].strip().split()\n",
    "                            else:\n",
    "                                city_name = location_parts[0].strip().split()[-1]\n",
    "                    \n",
    "                        return romaji_name, city_name\n",
    "\n",
    "    print(f'No instance of {place_name} station is found')\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Amagasaki', 'Amagasaki')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_romaji_name(\"尼崎\", \"28\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "translated_stations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_station(data):\n",
    "    translated_data = data.copy()\n",
    "    stat, city = get_romaji_name(data[\"name_kanji\"], data[\"prefecture\"])\n",
    "    translated_data[\"name_romaji\"] = stat\n",
    "    translated_data[\"city\"] = city\n",
    "\n",
    "    alternative_names = {\n",
    "        name: get_romaji_name(name, data[\"prefecture\"])[0] for name in data.get(\"alternative_names\", [])\n",
    "    }\n",
    "    translated_stations = []\n",
    "    for station in data[\"stations\"]:\n",
    "        # Copy station data to avoid modifying the original input\n",
    "        translated_station = station.copy()\n",
    "        # Add romaji name, based on the outer name_kanji (station group)\n",
    "        if translated_station[\"name_kanji\"] != data[\"name_kanji\"]:\n",
    "            translated_station[\"name_romaji\"] = alternative_names[translated_station[\"name_kanji\"]]\n",
    "        else:\n",
    "            translated_station[\"name_romaji\"] = translated_data[\"name_romaji\"]\n",
    "        # Append to translated_stations list\n",
    "        translated_stations.append(translated_station)\n",
    "\n",
    "    # Step 4: Add the translated stations to a new list in the translated data dictionary\n",
    "    translated_data[\"stations\"] = translated_stations\n",
    "\n",
    "    return translated_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = 1986"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 16/1230 [00:07<07:16,  2.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No instance of 三宮・花時計前 station is found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 19/1230 [00:10<14:01,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No instance of ハーバーランド station is found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 57/1230 [00:25<08:21,  2.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No instance of 天王寺駅前 station is found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 59/1230 [00:27<14:46,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No instance of 新今宮駅前 station is found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███▏      | 386/1230 [02:31<05:06,  2.75it/s]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(1986, len(stations))):\n",
    "    translated_stations.append(translate_station(stations[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"translated_stations_small.json\", \"w\", encoding=\"utf-8\") as of:\n",
    "    json.dump(translated_stations, of, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"translated_stations_test.json\", \"a\", encoding=\"utf-8\") as of:\n",
    "    json.dump(translated_stations[:1986], of, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually work each one of these:\n",
    "\n",
    "e.g. https://www.wikidata.org/w/api.php?action=wbsearchentities&format=json&language=en&search=%E9%A7%92%E5%B2%B3\n",
    "\n",
    "- 駒ケ岳 (Komagatake)\n",
    "- 幾寅 (Doesn't matter)\n",
    "- 落合 (Doesn't matter)\n",
    "- 月ケ岡 (Permanently closed)\n",
    "- 豊ケ岡 (Permanently closed)\n",
    "- 千代ケ岡 (Chiyogaoka)\n",
    "- 溝の口 (Mizonokuchi)\n",
    "- 新川崎 (Shin-Kawasaki)\n",
    "- 成田空港（第１旅客ターミナル） (Narita)\n",
    "- 空港第２ビル（第２旅客ターミナル） (Narita)\n",
    "- 鹿島サッカースタジアム（臨） (Kashima Soccer Stadium)\n",
    "- 電鉄富山駅・エスタ前 (Toyama)\n",
    "- 富山駅北 (Toyama)\n",
    "- 天王寺駅前 (Doesn't matter)\n",
    "- 新今宮駅前 (Doesn't matter)\n",
    "- 熊本駅前 (Doesn't matter)\n",
    "- 昭和町通り (Nishi-Urakami)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "1. Manually change \"-ku\" to actual city\n",
    "2. Osaka vs Ōsaka"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inaccurate translations provided by libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "寺: kana 'テラ', hiragana 'てら', romaji: 'tera'\n"
     ]
    }
   ],
   "source": [
    "kks = pykakasi.kakasi()\n",
    "result = kks.convert(text)\n",
    "for item in result:\n",
    "    print(\"{}: kana '{}', hiragana '{}', romaji: '{}'\".format(item['orig'], item['kana'], item['hira'], item['hepburn']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tera\n",
      "Tera\n",
      "Tera\n",
      "Tera\n",
      "Tera\n"
     ]
    }
   ],
   "source": [
    "katsu = cutlet.Cutlet()\n",
    "print(katsu.romaji(text))\n",
    "dicts = ['hepburn', 'kunrei', 'nippon', 'nihon']\n",
    "for d in dicts:\n",
    "    katsu = cutlet.Cutlet(d)\n",
    "    print(katsu.romaji(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
