{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO:\n",
    "1. Manually change \"-ku\" to actual city\n",
    "2. Osaka vs Ōsaka\n",
    "3. Change all prefecture 13 city to Tokyo\n",
    "4. Some city are represented by List\n",
    "5. Kyoto vs Kyōto\n",
    "6. `\"city\": \".*Ō.*\"`\n",
    "7. Ōdate, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# from fuzzywuzzy import fuzz\n",
    "import requests\n",
    "from requests.exceptions import HTTPError\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsF = open(\"translated_stations_test.json\")\n",
    "stations = json.load(stationsF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_long_vowels(text: str):\n",
    "    return text.replace(\"Ō\", \"O\").replace(\"ō\", \"o\").replace(\"Ū\", \"U\").replace(\"ū\", \"u\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in stations:\n",
    "    if isinstance(s['city'], list):\n",
    "        if len(s['city']) == 1:\n",
    "            # If there's only one item in the list, assign it as the city name\n",
    "            s['city'] = normalize_long_vowels(s['city'][0])\n",
    "        elif len(s['city']) > 1:\n",
    "            # If there are multiple items in the list, set 'city' to None\n",
    "            s['city'] = None\n",
    "    if isinstance(s['city'], str):\n",
    "        s['city'] = normalize_long_vowels(s['city'])\n",
    "    # Extreme special case\n",
    "    if s['city'] == 'Koda':\n",
    "        s['city'] = 'Koda'\n",
    "    if s['city'] == 'Nan\\'yo':\n",
    "        s['city'] = 'Nanyo'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"translated_stations_normalized.json\", \"w\", encoding=\"utf-8\") as of:\n",
    "    json.dump(stations, of, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add prefectures info to shinkansen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DONE: There are stations with same name in different prefectures. This leads to error in the \"translated_stations_normalized.json\" data. Need to redo the addition. (Manually modified JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations_to_add = []\n",
    "s1 = [\"東京\", \"品川\", \"新横浜\", \"小田原\", \"熱海\", \"三島\", \"新富士\", \"静岡\", \"掛川\", \"浜松\", \"豊橋\", \"三河安城\", \"名古屋\", \"岐阜羽島\", \"米原\", \"京都\", \"新大阪\"]\n",
    "stations_to_add.append(s1)\n",
    "s2 = [\"新大阪\", \"新神戸\", \"西明石\", \"姫路\", \"相生\", \"岡山\", \"新倉敷\", \"福山\", \"新尾道\", \"三原\", \"東広島\", \"広島\", \"新岩国\", \"徳山\", \"新山口\", \"厚狭\", \"新下関\", \"小倉\", \"博多\"]\n",
    "stations_to_add.append(s2)\n",
    "s3 = [\"東京\", \"上野\", \"大宮\", \"小山\", \"宇都宮\", \"那須塩原\", \"新白河\", \"郡山\", \"福島\", \"白石蔵王\", \"仙台\", \"古川\", \"くりこま高原\", \"一ノ関\", \"水沢江刺\", \"北上\", \"新花巻\", \"盛岡\", \"いわて沼宮内\", \"二戸\", \"八戸\", \"七戸十和田\", \"新青森\"]\n",
    "stations_to_add.append(s3)\n",
    "s4 = [\"東京\", \"上野\", \"大宮\", \"熊谷\", \"本庄早稲田\", \"高崎\", \"上毛高原\", \"越後湯沢\", \"浦佐\", \"長岡\", \"燕三条\", \"新潟\"]\n",
    "stations_to_add.append(s4)\n",
    "s5 = []\n",
    "# s5 = [\"越後湯沢\", \"ガーラ湯沢\"]\n",
    "stations_to_add.append(s5)\n",
    "s6 = [\"福島\", \"米沢\", \"高畠\", \"赤湯\", \"かみのやま温泉\", \"山形\", \"天童\", \"さくらんぼ東根\", \"村山\", \"大石田\", \"新庄\"]\n",
    "stations_to_add.append(s6)\n",
    "s7 = [\"東京\", \"上野\", \"大宮\", \"小山\", \"宇都宮\", \"那須塩原\", \"新白河\", \"郡山\", \"福島\", \"白石蔵王\", \"仙台\", \"古川\", \"くりこま高原\", \"一ノ関\", \"水沢江刺\", \"北上\", \"新花巻\", \"盛岡\", \"雫石\", \"田沢湖\", \"角館\", \"大曲\", \"秋田\"]\n",
    "stations_to_add.append(s7)\n",
    "s8 = [\"東京\", \"上野\", \"大宮\", \"熊谷\", \"本庄早稲田\", \"高崎\", \"安中榛名\", \"軽井沢\", \"佐久平\", \"上田\", \"長野\", \"飯山\", \"上越妙高\", \"糸魚川\", \"黒部宇奈月温泉\", \"富山\", \"新高岡\", \"金沢\", \"小松\", \"加賀温泉\", \"芦原温泉\", \"福井\", \"越前たけふ\", \"敦賀\", \"東小浜\", \"京都\", \"松井山手\", \"新大阪\"]\n",
    "stations_to_add.append(s8)\n",
    "s9 = [\"博多\", \"新鳥栖\", \"久留米\", \"筑後船小屋\", \"新大牟田\", \"新玉名\", \"熊本\", \"新八代\", \"新水俣\", \"出水\", \"川内\", \"鹿児島中央\"]\n",
    "stations_to_add.append(s9)\n",
    "s10 = [\"新青森\", \"奥津軽いまべつ\", \"木古内\", \"新函館北斗\"]\n",
    "stations_to_add.append(s10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_shinkansen_prefectures(stations: list[str], line: dict, stations_data_json: list[dict]):\n",
    "    line_name = line[\"name_kanji\"]\n",
    "    line_id = line[\"ekidata_id\"]\n",
    "    prefectures = set()\n",
    "    if stations is None:\n",
    "        return\n",
    "\n",
    "    for i, st in enumerate(stations):\n",
    "        found = False\n",
    "        for station_data in stations_data_json:\n",
    "            # Check if station name matches any entry in station_data\n",
    "            if station_data.get(\"name_kanji\") == st or st in station_data.get(\"alternative_names\", []):\n",
    "                if found:\n",
    "                    print(f\"Station {st} was processed twice for line {line_name}, id {line_id}\")\n",
    "                    # break\n",
    "                    continue\n",
    "                found = True\n",
    "                if line_id not in station_data[\"ekidata_line_ids\"]:\n",
    "                    print(f\"Station {st} in prefecture {station_data['prefecture']} is passed\")\n",
    "                    continue\n",
    "                # Get details for the existing station entry\n",
    "                cur_prefecture = station_data[\"prefecture\"]\n",
    "                # print(f\"For line {line_name}, station {st} is found in prefecture {cur_prefecture}\")\n",
    "                prefectures.add(cur_prefecture)\n",
    "                line[\"prefectures\"] = list(prefectures)\n",
    "                \n",
    "                # Break after finding and processing the correct station\n",
    "                # break\n",
    "\n",
    "        if not found:\n",
    "            print(f\"Station {st} is not found for line {line_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Station 新富士 in prefecture 01 is passed\n",
      "Station 岐阜羽島 is not found for line 東海道新幹線\n",
      "Station 新尾道 is not found for line 山陽新幹線\n",
      "Station 東広島 is not found for line 山陽新幹線\n",
      "Station 新岩国 is not found for line 山陽新幹線\n",
      "Station 郡山 was processed twice for line 東北新幹線, id 1004\n",
      "Station 福島 was processed twice for line 東北新幹線, id 1004\n",
      "Station 白石蔵王 is not found for line 東北新幹線\n",
      "Station くりこま高原 is not found for line 東北新幹線\n",
      "Station 水沢江刺 is not found for line 東北新幹線\n",
      "Station 七戸十和田 is not found for line 東北新幹線\n",
      "Station 本庄早稲田 is not found for line 上越新幹線\n",
      "Station 上毛高原 is not found for line 上越新幹線\n",
      "Station 福島 was processed twice for line 山形新幹線, id 1007\n",
      "Station 郡山 was processed twice for line 秋田新幹線, id 1008\n",
      "Station 福島 was processed twice for line 秋田新幹線, id 1008\n",
      "Station 白石蔵王 is not found for line 秋田新幹線\n",
      "Station くりこま高原 is not found for line 秋田新幹線\n",
      "Station 水沢江刺 is not found for line 秋田新幹線\n",
      "Station 本庄早稲田 is not found for line 北陸新幹線\n",
      "Station 安中榛名 is not found for line 北陸新幹線\n",
      "Station 黒部宇奈月温泉 is not found for line 北陸新幹線\n",
      "Station 越前たけふ is not found for line 北陸新幹線\n",
      "Station 新大牟田 is not found for line 九州新幹線\n",
      "Station 新玉名 is not found for line 九州新幹線\n",
      "Station 奥津軽いまべつ is not found for line 北海道新幹線\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    add_shinkansen_prefectures(stations_to_add[i], lines[i], stations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1002\",\n",
      "    \"name_kanji\": \"東海道新幹線\",\n",
      "    \"name_kana\": \"とうかいどうしんかんせん\",\n",
      "    \"name_romaji\": \"Tokaido Shinkansen\",\n",
      "    \"alternative_names\": [\n",
      "        \"トウカイドウシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [\n",
      "        \"25\",\n",
      "        \"22\",\n",
      "        \"14\",\n",
      "        \"27\",\n",
      "        \"13\",\n",
      "        \"26\",\n",
      "        \"23\"\n",
      "    ],\n",
      "    \"logo\": \"\"\n",
      "}\n",
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1003\",\n",
      "    \"name_kanji\": \"山陽新幹線\",\n",
      "    \"name_kana\": \"さんようしんかんせん\",\n",
      "    \"name_romaji\": \"San'yo Shinkansen\",\n",
      "    \"alternative_names\": [\n",
      "        \"サンヨウシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [\n",
      "        \"40\",\n",
      "        \"28\",\n",
      "        \"34\",\n",
      "        \"35\",\n",
      "        \"27\",\n",
      "        \"33\"\n",
      "    ],\n",
      "    \"logo\": \"\"\n",
      "}\n",
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1004\",\n",
      "    \"name_kanji\": \"東北新幹線\",\n",
      "    \"name_kana\": \"とうほくしんかんせん\",\n",
      "    \"name_romaji\": \"Tohoku Shinkansen\",\n",
      "    \"alternative_names\": [\n",
      "        \"トウホクシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [\n",
      "        \"02\",\n",
      "        \"07\",\n",
      "        \"13\",\n",
      "        \"04\",\n",
      "        \"03\",\n",
      "        \"09\",\n",
      "        \"11\"\n",
      "    ],\n",
      "    \"logo\": \"\"\n",
      "}\n",
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1005\",\n",
      "    \"name_kanji\": \"上越新幹線\",\n",
      "    \"name_kana\": \"じょうえつしんかんせん\",\n",
      "    \"name_romaji\": \"Joetsu Shinkansen\",\n",
      "    \"alternative_names\": [\n",
      "        \"ジョウエツシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [\n",
      "        \"13\",\n",
      "        \"10\",\n",
      "        \"15\",\n",
      "        \"11\"\n",
      "    ],\n",
      "    \"logo\": \"\"\n",
      "}\n",
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1006\",\n",
      "    \"name_kanji\": \"上越新幹線(ガーラ湯沢支線)\",\n",
      "    \"name_kana\": \"\",\n",
      "    \"name_romaji\": \"\",\n",
      "    \"alternative_names\": [\n",
      "        \"ジョウエツシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [],\n",
      "    \"logo\": \"\"\n",
      "}\n",
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1007\",\n",
      "    \"name_kanji\": \"山形新幹線\",\n",
      "    \"name_kana\": \"やまがたしんかんせん\",\n",
      "    \"name_romaji\": \"Yamagata Shinkansen\",\n",
      "    \"alternative_names\": [\n",
      "        \"ヤマガタシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [\n",
      "        \"07\",\n",
      "        \"06\"\n",
      "    ],\n",
      "    \"logo\": \"\"\n",
      "}\n",
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1008\",\n",
      "    \"name_kanji\": \"秋田新幹線\",\n",
      "    \"name_kana\": \"あきたしんかんせん\",\n",
      "    \"name_romaji\": \"Akita Shinkansen\",\n",
      "    \"alternative_names\": [\n",
      "        \"アキタシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [\n",
      "        \"05\",\n",
      "        \"07\",\n",
      "        \"13\",\n",
      "        \"04\",\n",
      "        \"03\",\n",
      "        \"09\",\n",
      "        \"11\"\n",
      "    ],\n",
      "    \"logo\": \"\"\n",
      "}\n",
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1009\",\n",
      "    \"name_kanji\": \"北陸新幹線\",\n",
      "    \"name_kana\": \"ほくりくしんかんせん\",\n",
      "    \"name_romaji\": \"Hokuriku Shinkansen\",\n",
      "    \"alternative_names\": [\n",
      "        \"ホクリクシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [\n",
      "        \"15\",\n",
      "        \"20\",\n",
      "        \"18\",\n",
      "        \"27\",\n",
      "        \"13\",\n",
      "        \"10\",\n",
      "        \"26\",\n",
      "        \"17\",\n",
      "        \"16\",\n",
      "        \"11\"\n",
      "    ],\n",
      "    \"logo\": \"\"\n",
      "}\n",
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1010\",\n",
      "    \"name_kanji\": \"九州新幹線\",\n",
      "    \"name_kana\": \"きゅうしゅうしんかんせん\",\n",
      "    \"name_romaji\": \"Kyushu Shinkansen\",\n",
      "    \"alternative_names\": [\n",
      "        \"キュウシュウシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [\n",
      "        \"41\",\n",
      "        \"40\",\n",
      "        \"43\",\n",
      "        \"46\"\n",
      "    ],\n",
      "    \"logo\": \"\"\n",
      "}\n",
      "{\n",
      "    \"code\": \"\",\n",
      "    \"ekidata_id\": \"1011\",\n",
      "    \"name_kanji\": \"北海道新幹線\",\n",
      "    \"name_kana\": \"ほっかいどうしんかんせん\",\n",
      "    \"name_romaji\": \"Hokkaido Shinkansen\",\n",
      "    \"alternative_names\": [\n",
      "        \"ホッカイドウシンカンセン\"\n",
      "    ],\n",
      "    \"prefectures\": [\n",
      "        \"01\",\n",
      "        \"02\"\n",
      "    ],\n",
      "    \"logo\": \"\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(json.dumps(lines[i], ensure_ascii=False, indent=4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"processed_lines.json\", \"w\", encoding=\"utf-8\") as of:\n",
    "    json.dump(lines, of, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find \"largest\" station for each city\n",
    "\n",
    "By \"largest\", we mean the station that can reach the most prefectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsF = open(\"translated_stations_normalized.json\")\n",
    "stations = json.load(stationsF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "linesF = open(\"processed_lines.json\")\n",
    "lines = json.load(linesF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "幾寅 is not processed because city name is not found\n",
      "落合 is not processed because city name is not found\n",
      "月ケ岡 is not processed because city name is not found\n",
      "豊ケ岡 is not processed because city name is not found\n",
      "鹿折唐桑 is not processed because city name is not found\n",
      "脇ノ沢 is not processed because city name is not found\n",
      "小友 is not processed because city name is not found\n",
      "細浦 is not processed because city name is not found\n",
      "下船渡 is not processed because city name is not found\n",
      "大船渡 is not processed because city name is not found\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "stations_by_city = defaultdict(list)  # (city: list(stations))\n",
    "\n",
    "for s in stations:\n",
    "    try:\n",
    "        cur_city = s['city'] + \"---\" + s['prefecture']\n",
    "        stations_by_city[cur_city].append(s)\n",
    "    except:\n",
    "        print(f'{s[\"name_kanji\"]} is not processed because city name is not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "795\n"
     ]
    }
   ],
   "source": [
    "print(len(stations_by_city))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "biggest_stations = {}  # city: (num_prefectures, list(station))\n",
    "need_processing = []  # city names that require further attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prefectures(line_id):\n",
    "    for line in lines:\n",
    "        if line['ekidata_id'] == line_id:\n",
    "            return line['prefectures']\n",
    "    raise KeyError(f\"{line_id} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Calculate total reachable prefectures for each city\n",
    "for ctys, stns in stations_by_city.items():\n",
    "    all_reachable_prefectures = set()\n",
    "    station_reach_count = {}  # {station_id: count of unique prefectures it can reach}\n",
    "    all_stations_reach_one = True  # Flag to retain all if all reach only their own prefecture\n",
    "\n",
    "    # Step 2: Track unique prefectures reachable by each station and accumulate all for the city\n",
    "    for st in stns:\n",
    "        lines_available = st['ekidata_line_ids']\n",
    "        reachable = set()\n",
    "        \n",
    "        # Update reach of this station\n",
    "        for line in lines_available:\n",
    "            reachable.update(get_prefectures(line))\n",
    "        \n",
    "        # Track how many unique prefectures each station can reach\n",
    "        uid = st['name_romaji'] + \"---\" + st['prefecture']\n",
    "        station_reach_count[uid] = len(reachable)\n",
    "        \n",
    "        # Check if any station reaches more than its own prefecture\n",
    "        if len(reachable) > 1:\n",
    "            all_stations_reach_one = False\n",
    "        \n",
    "        # Accumulate unique reachable prefectures for the city\n",
    "        all_reachable_prefectures.update(reachable)\n",
    "\n",
    "    # Step 3: Check if all stations reach only one prefecture\n",
    "    if all_stations_reach_one:\n",
    "        # Retain all stations in `biggest_stations` for this city\n",
    "        best_stations = stns\n",
    "    else:\n",
    "        # Select top 5 stations with the highest reach count and ensure uniqueness\n",
    "        top_stations = sorted(station_reach_count.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "        \n",
    "        # Use a dictionary to store unique stations\n",
    "        unique_best_stations = {}\n",
    "        \n",
    "        # Populate the unique stations dictionary\n",
    "        for uid, _ in top_stations:\n",
    "            for station in stns:\n",
    "                station_uid = station['name_romaji'] + \"---\" + station['prefecture']\n",
    "                if station_uid == uid:\n",
    "                    unique_best_stations[station_uid] = station  # Retains only unique stations\n",
    "        \n",
    "        # Convert unique stations dictionary back to a list\n",
    "        best_stations = list(unique_best_stations.values())\n",
    "\n",
    "    # Step 4: Add city to `need_processing` if it only reaches one prefecture\n",
    "    if len(all_reachable_prefectures) == 1:\n",
    "        need_processing.append(ctys)\n",
    "    \n",
    "    # Assign results to `biggest_stations`\n",
    "    biggest_stations[ctys] = (len(all_reachable_prefectures), best_stations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "print(len(biggest_stations[\"Noshiro---05\"][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "98\n"
     ]
    }
   ],
   "source": [
    "print(len(need_processing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No station with name containing 'Minamifurano' found in Minamifurano---01, first station is picked\n",
      "No station with name containing 'Shinhidaka' found in Shinhidaka---01, first station is picked\n",
      "No station with name containing 'Ozora' found in Ozora---01, first station is picked\n"
     ]
    }
   ],
   "source": [
    "from fuzzywuzzy import fuzz\n",
    "# MATCH_THRESHOLD = 50\n",
    "finished_processing = []\n",
    "\n",
    "for cty in need_processing: \n",
    "    curr_selection = biggest_stations[cty][1]\n",
    "    if len(curr_selection) == 1:\n",
    "        finished_processing.append(cty)\n",
    "        continue\n",
    "    st_names = {st['name_romaji']: st for st in curr_selection}\n",
    "    city_name = cty[:-5]  # Extract city name from cty\n",
    "    \n",
    "    # Check if any station matches the city name exactly\n",
    "    if city_name in st_names.keys():\n",
    "        biggest_stations[cty] = (1, [st_names[city_name]])\n",
    "        finished_processing.append(cty)\n",
    "    else:\n",
    "        # Find stations where the city name appears in the station's romaji name\n",
    "        partial_matches = [\n",
    "            st for st in curr_selection \n",
    "            if fuzz.partial_ratio(city_name.lower(), st['name_romaji'].lower()) >= (len(city_name) - 2) / len(city_name) * 100\n",
    "        ]\n",
    "        \n",
    "        if partial_matches:\n",
    "            # Pick the first match or apply any additional ranking if needed\n",
    "            biggest_stations[cty] = (1, partial_matches)\n",
    "            finished_processing.append(cty)\n",
    "        else:\n",
    "            # If no partial match found, keep the original list and log a message\n",
    "            biggest_stations[cty] = (1, [biggest_stations[cty][1][0]])\n",
    "            finished_processing.append(cty)\n",
    "            print(f\"No station with name containing '{city_name}' found in {cty}, first station is picked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No station with a name similar to 'Misato' found in Misato---05, first station in the list is picked\n",
      "No station with a name similar to 'Kitaakita' found in Kitaakita---05, first station in the list is picked\n",
      "No station with a name similar to 'Hirakawa' found in Hirakawa---02, first station in the list is picked\n",
      "No station with a name similar to 'Happo' found in Happo---05, first station in the list is picked\n",
      "No station with a name similar to 'Tsugaru' found in Tsugaru---02, first station in the list is picked\n",
      "No station with a name similar to 'Nishiwaga' found in Nishiwaga---03, first station in the list is picked\n",
      "No station with a name similar to 'Takizawa' found in Takizawa---03, first station in the list is picked\n",
      "No station with a name similar to 'Semboku' found in Semboku---05, first station in the list is picked\n",
      "No station with a name similar to 'Agano' found in Agano---15, first station in the list is picked\n",
      "No station with a name similar to 'Tainai' found in Tainai---15, first station in the list is picked\n",
      "No station with a name similar to 'Shonai' found in Shonai---06, first station in the list is picked\n",
      "No station with a name similar to 'Yurihonjo' found in Yurihonjo---05, first station in the list is picked\n",
      "No station with a name similar to 'Nanyo' found in Nanyo---06, first station in the list is picked\n",
      "No station with a name similar to 'Kawanishi' found in Kawanishi---06, first station in the list is picked\n",
      "No station with a name similar to 'Iide' found in Iide---06, first station in the list is picked\n",
      "No station with a name similar to 'Sekikawa' found in Sekikawa---15, first station in the list is picked\n",
      "No station with a name similar to 'Nishiaizu' found in Nishiaizu---07, first station in the list is picked\n",
      "No station with a name similar to 'Aizumisato' found in Aizumisato---07, first station in the list is picked\n",
      "No station with a name similar to 'Mishima' found in Mishima---07, first station in the list is picked\n",
      "No station with a name similar to 'Kaneyama' found in Kaneyama---07, first station in the list is picked\n",
      "No station with a name similar to 'Hitachinaka' found in Hitachinaka---08, first station in the list is picked\n",
      "No station with a name similar to 'Kitaibaraki' found in Kitaibaraki---08, first station in the list is picked\n",
      "No station with a name similar to 'Naraha' found in Naraha---07, first station in the list is picked\n",
      "No station with a name similar to 'Minamisoma' found in Minamisoma---07, first station in the list is picked\n",
      "No station with a name similar to 'Kunimi' found in Kunimi---07, first station in the list is picked\n",
      "No station with a name similar to 'Shibata' found in Shibata---04, first station in the list is picked\n",
      "No station with a name similar to 'Kurihara' found in Kurihara---04, first station in the list is picked\n",
      "No station with a name similar to 'Oshu' found in Oshu---03, first station in the list is picked\n",
      "No station with a name similar to 'Sagamihara' found in Sagamihara---14, first station in the list is picked\n",
      "No station with a name similar to 'Fuefuki' found in Fuefuki---19, first station in the list is picked\n",
      "No station with a name similar to 'Hokuto' found in Hokuto---19, first station in the list is picked\n",
      "No station with a name similar to 'Sammu' found in Sammu---12, first station in the list is picked\n",
      "No station with a name similar to 'Sosa' found in Sosa---12, first station in the list is picked\n",
      "No station with a name similar to 'Shimotsuke' found in Shimotsuke---09, first station in the list is picked\n",
      "No station with a name similar to 'Hitachiomiya' found in Hitachiomiya---08, first station in the list is picked\n",
      "No station with a name similar to 'Tamakawa' found in Tamakawa---07, first station in the list is picked\n",
      "No station with a name similar to 'Chikusei' found in Chikusei---08, first station in the list is picked\n",
      "No station with a name similar to 'Sakuragawa' found in Sakuragawa---08, first station in the list is picked\n",
      "No station with a name similar to 'Nanmoku' found in Nanmoku---20, first station in the list is picked\n",
      "No station with a name similar to 'Sakuho' found in Sakuho---20, first station in the list is picked\n",
      "No station with a name similar to 'Nanbu' found in Nanbu---19, first station in the list is picked\n",
      "No station with a name similar to 'Ichikawamisato' found in Ichikawamisato---19, first station in the list is picked\n",
      "No station with a name similar to 'Chuo' found in Chuo---19, first station in the list is picked\n",
      "No station with a name similar to 'Showa' found in Showa---19, first station in the list is picked\n",
      "No station with a name similar to 'Nakano' found in Nakano---20, first station in the list is picked\n",
      "No station with a name similar to 'Sakae' found in Sakae---20, first station in the list is picked\n",
      "No station with a name similar to 'Tenryu' found in Tenryu---20, first station in the list is picked\n",
      "No station with a name similar to 'Yasuoka' found in Yasuoka---20, first station in the list is picked\n",
      "No station with a name similar to 'Iida' found in Iida---20, first station in the list is picked\n",
      "No station with a name similar to 'Minamiechizen' found in Minamiechizen---18, first station in the list is picked\n",
      "No station with a name similar to 'Echizen' found in Echizen---18, first station in the list is picked\n",
      "No station with a name similar to 'Sakai' found in Sakai---18, first station in the list is picked\n",
      "No station with a name similar to 'Hakusan' found in Hakusan---17, first station in the list is picked\n",
      "No station with a name similar to 'Minokamo' found in Minokamo---21, first station in the list is picked\n",
      "No station with a name similar to 'Kosai' found in Kosai---22, first station in the list is picked\n",
      "No station with a name similar to 'Suzuka' found in Suzuka---24, first station in the list is picked\n",
      "No station with a name similar to 'Minamiyamashiro' found in Minamiyamashiro---26, first station in the list is picked\n",
      "No station with a name similar to 'Kihoku' found in Kihoku---24, first station in the list is picked\n",
      "No station with a name similar to 'Konan' found in Konan---25, first station in the list is picked\n",
      "No station with a name similar to 'Asakuchi' found in Asakuchi---33, first station in the list is picked\n",
      "No station with a name similar to 'Higashihiroshima' found in Higashihiroshima---34, first station in the list is picked\n",
      "No station with a name similar to 'Nantan' found in Nantan---26, first station in the list is picked\n",
      "No station with a name similar to 'Kyotamba' found in Kyotamba---26, first station in the list is picked\n",
      "No station with a name similar to 'Asago' found in Asago---28, first station in the list is picked\n",
      "No station with a name similar to 'Shin'onsen' found in Shin'onsen---28, first station in the list is picked\n",
      "No station with a name similar to 'Yurihama' found in Yurihama---31, first station in the list is picked\n",
      "No station with a name similar to 'Hokuei' found in Hokuei---31, first station in the list is picked\n",
      "No station with a name similar to 'District' found in District---31, first station in the list is picked\n",
      "No station with a name similar to 'Seika' found in Seika---26, first station in the list is picked\n",
      "No station with a name similar to 'Hirakata' found in Hirakata---27, first station in the list is picked\n",
      "No station with a name similar to 'Katano' found in Katano---27, first station in the list is picked\n",
      "No station with a name similar to 'Daito' found in Daito---27, first station in the list is picked\n",
      "No station with a name similar to 'Ide' found in Ide---26, first station in the list is picked\n",
      "No station with a name similar to 'Izumisano' found in Izumisano---27, first station in the list is picked\n",
      "No station with a name similar to 'Sennan' found in Sennan---27, first station in the list is picked\n",
      "No station with a name similar to 'Hannan' found in Hannan---27, first station in the list is picked\n",
      "No station with a name similar to 'Setouchi' found in Setouchi---33, first station in the list is picked\n",
      "No station with a name similar to 'Katsuragi' found in Katsuragi---30, first station in the list is picked\n",
      "No station with a name similar to 'Abu' found in Abu---35, first station in the list is picked\n",
      "No station with a name similar to 'Nichinan' found in Nichinan---31, first station in the list is picked\n",
      "No station with a name similar to 'Hino' found in Hino---31, first station in the list is picked\n",
      "No station with a name similar to 'Yazu' found in Yazu---31, first station in the list is picked\n",
      "No station with a name similar to 'Unnan' found in Unnan---32, first station in the list is picked\n",
      "No station with a name similar to 'Okuizumo' found in Okuizumo---32, first station in the list is picked\n",
      "No station with a name similar to 'Akitakata' found in Akitakata---34, first station in the list is picked\n",
      "No station with a name similar to 'Miyoshi' found in Miyoshi---36, first station in the list is picked\n",
      "No station with a name similar to 'Nankoku' found in Nankoku---39, first station in the list is picked\n",
      "No station with a name similar to 'Hidaka' found in Hidaka---39, first station in the list is picked\n",
      "No station with a name similar to 'Higashikagawa' found in Higashikagawa---37, first station in the list is picked\n",
      "No station with a name similar to 'Naruto' found in Naruto---36, first station in the list is picked\n",
      "No station with a name similar to 'Shikokuchuo' found in Shikokuchuo---38, first station in the list is picked\n",
      "No station with a name similar to 'Matsuno' found in Matsuno---38, first station in the list is picked\n",
      "No station with a name similar to 'Fukutsu' found in Fukutsu---40, first station in the list is picked\n",
      "No station with a name similar to 'Chikushino' found in Chikushino---40, first station in the list is picked\n",
      "No station with a name similar to 'Uki' found in Uki---43, first station in the list is picked\n",
      "No station with a name similar to 'Chikujo' found in Chikujo---40, first station in the list is picked\n",
      "No station with a name similar to 'Soo' found in Soo---46, first station in the list is picked\n",
      "No station with a name similar to 'Itoshima' found in Itoshima---40, first station in the list is picked\n",
      "No station with a name similar to 'Kusu' found in Kusu---44, first station in the list is picked\n",
      "No station with a name similar to 'Kokonoe' found in Kokonoe---44, first station in the list is picked\n",
      "No station with a name similar to 'Toho' found in Toho---40, first station in the list is picked\n",
      "No station with a name similar to 'Kikuyo' found in Kikuyo---43, first station in the list is picked\n",
      "No station with a name similar to 'Bungoono' found in Bungoono---44, first station in the list is picked\n",
      "No station with a name similar to 'Ashikita' found in Ashikita---43, first station in the list is picked\n",
      "No station with a name similar to 'Kuma' found in Kuma---43, first station in the list is picked\n"
     ]
    }
   ],
   "source": [
    "# MATCH_THRESHOLD = 50\n",
    "need_processing = []\n",
    "# Process biggest_stations to handle multiple stations with the same max reachable prefectures\n",
    "for cty, (num_prefectures, stations) in biggest_stations.items():\n",
    "    # If there's only one best station, we keep it as is\n",
    "    if len(stations) == 1:\n",
    "        continue\n",
    "    \n",
    "    city_name = cty.split(\"---\")[0]  # Extract the city name portion from the key\n",
    "    # print(city_name.lower())\n",
    "    # Find stations where the name closely matches the city name\n",
    "    full_matches = [st for st in stations if city_name.lower() == st['name_romaji'].lower()]\n",
    "    partial_matches = [\n",
    "        st for st in stations\n",
    "        if fuzz.partial_ratio(city_name.lower(), st['name_romaji'].lower()) >= (len(city_name) - 2) / len(city_name) * 100\n",
    "    ]\n",
    "    if full_matches:\n",
    "        biggest_stations[cty] = (num_prefectures, [full_matches[0]])  # Keep only the first match\n",
    "    # If we have at least one partial match, choose the first one (or apply a selection strategy)\n",
    "    elif partial_matches:\n",
    "        biggest_stations[cty] = (num_prefectures, [partial_matches[0]])  # Keep only the first match\n",
    "    else:\n",
    "        # If no fuzzy match is found, return the first one\n",
    "        biggest_stations[cty] = (num_prefectures, [biggest_stations[cty][1][0]])\n",
    "        print(f\"No station with a name similar to '{city_name}' found in {cty}, first station in the list is picked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_best_stations = {}\n",
    "\n",
    "for city_key, (prefecture_count, stations) in biggest_stations.items():\n",
    "    # Prepare a list to store the cleaned information for each station\n",
    "    cleaned_stations = []\n",
    "\n",
    "    for station in stations:\n",
    "        # For lat/lon, use the first element in the `stations` field if it exists\n",
    "        if station['stations']:\n",
    "            station_info = station['stations'][0]\n",
    "        else:\n",
    "            station_info = {}\n",
    "\n",
    "        # Gather the necessary fields for each station\n",
    "        cleaned_station = {\n",
    "            \"name_kanji\": station.get(\"name_kanji\", \"\"),\n",
    "            \"name_romaji\": station.get(\"name_romaji\", \"\"),\n",
    "            \"city\": station.get(\"city\", \"\"),\n",
    "            \"prefecture\": station.get(\"prefecture\", \"\"),\n",
    "            \"ekidata_line_ids\": station.get(\"ekidata_line_ids\", []),\n",
    "            # \"lat\": station_info.get(\"lat\", None),\n",
    "            # \"lon\": station_info.get(\"lon\", None),\n",
    "        }\n",
    "        \n",
    "        cleaned_stations.append(cleaned_station)\n",
    "\n",
    "    # Create a new entry with the \"reachable\" prefecture count and the list of cleaned stations\n",
    "    cleaned_best_stations[city_key] = {\n",
    "        \"reachable\": prefecture_count,\n",
    "        \"stations\": cleaned_stations\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"biggest_stations_big.json\", \"w\", encoding=\"utf-8\") as of:\n",
    "    json.dump(cleaned_best_stations, of, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add station's ID corresponding to each line, add line names in case needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "stationsF = open(\"translated_stations_normalized.json\")\n",
    "stations = json.load(stationsF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "linesF = open(\"processed_lines.json\")\n",
    "lines = json.load(linesF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestStatF = open(\"biggest_stations_big.json\")\n",
    "best_stations = json.load(bestStatF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefF = open(\"open-data-jp-prefectures-master/prefectures.json\")\n",
    "prefectures = json.load(prefF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'01': 'Hokkaido', '02': 'Aomori', '03': 'Iwate', '04': 'Miyagi', '05': 'Akita', '06': 'Yamagata', '07': 'Fukushima', '08': 'Ibaraki', '09': 'Tochigi', '10': 'Gunma', '11': 'Saitama', '12': 'Chiba', '13': 'Tokyo', '14': 'Kanagawa', '15': 'Niigata', '16': 'Toyama', '17': 'Ishikawa', '18': 'Fukui', '19': 'Yamanashi', '20': 'Nagano', '21': 'Gifu', '22': 'Shizuoka', '23': 'Aichi', '24': 'Mie', '25': 'Shiga', '26': 'Kyoto', '27': 'Osaka', '28': 'Hyōgo', '29': 'Nara', '30': 'Wakayama', '31': 'Tottori', '32': 'Shimane', '33': 'Okayama', '34': 'Hiroshima', '35': 'Yamaguchi', '36': 'Tokushima', '37': 'Kagawa', '38': 'Ehime', '39': 'Kōchi', '40': 'Fukuoka', '41': 'Saga', '42': 'Nagasaki', '43': 'Kumamoto', '44': 'Ōita', '45': 'Miyazaki', '46': 'Kagoshima', '47': 'Okinawa'}\n"
     ]
    }
   ],
   "source": [
    "prefecture_dict = {}\n",
    "\n",
    "for prefecture in prefectures:\n",
    "    iso_code = prefecture[\"iso\"]\n",
    "    # Split romaji and exclude the last word if more than one word\n",
    "    romaji_parts = prefecture[\"prefecture_romaji\"].split()\n",
    "    if len(romaji_parts) > 1:\n",
    "        romaji_name = \" \".join(romaji_parts[:-1])\n",
    "    else:\n",
    "        romaji_name = romaji_parts[0]  # For single-word cases like \"Hokkaido\"\n",
    "    \n",
    "    # Store in dictionary\n",
    "    prefecture_dict[iso_code] = romaji_name\n",
    "\n",
    "# Output the result\n",
    "print(prefecture_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_station(st_info):\n",
    "    name = st_info['name_kanji']\n",
    "    pref = st_info['prefecture']\n",
    "    for st in stations:\n",
    "        if st['name_kanji'] == name and st['prefecture'] == pref:\n",
    "            return st['stations']\n",
    "    print(f'station with {name} and in prefecture {pref} is not found')\n",
    "    return None\n",
    "\n",
    "def find_line(line_id):\n",
    "    for l in lines:\n",
    "        if l['ekidata_id'] == line_id:\n",
    "            return l['name_kanji']\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "recorded_line_stations = defaultdict(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "for city_pref, city_info in best_stations.items():\n",
    "    # Iterate over each station in the list of stations for this city\n",
    "    for station in city_info['stations']:\n",
    "        stations_info = find_station(station)\n",
    "        \n",
    "        # Check if `stations_info` is None and handle accordingly\n",
    "        if stations_info is None:\n",
    "            print(f\"Something strange happened with station {station['name_kanji']}\")\n",
    "            continue\n",
    "        \n",
    "        # Prepare lists to store `ekidata_line_ids` and `line_names` for the current station\n",
    "        new_ids = []\n",
    "        line_names = []\n",
    "        \n",
    "        # Process each related station info for current station\n",
    "        for s_info in stations_info:\n",
    "            # Generate new id format and record it\n",
    "            new_id = s_info['ekidata_id'][:-2] + \"---\" + s_info['ekidata_id'][-2:]\n",
    "            new_ids.append(new_id)\n",
    "            \n",
    "            # Update `recorded_line_stations` with current station data\n",
    "            recorded_line_stations[int(s_info['ekidata_id'][:-2])].append(int(s_info['ekidata_id'][-2:]))\n",
    "            \n",
    "            # Find and store the line name for the current station\n",
    "            line_name = find_line(s_info['ekidata_line_id'])\n",
    "            line_names.append(line_name)\n",
    "        \n",
    "        # Assign `ekidata_line_ids` and `line_names` to the current station\n",
    "        station['ekidata_line_ids'] = new_ids\n",
    "        station['line_names'] = line_names\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"biggest_stations_big.json\", \"w\", encoding=\"utf-8\") as of:\n",
    "    json.dump(best_stations, of, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "bestStatF = open(\"biggest_stations_big.json\")\n",
    "best_stations = json.load(bestStatF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, ls in recorded_line_stations.items():\n",
    "    ls.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_st_on_lineid(line, id):\n",
    "    search = f\"{line}---{id:02}\"\n",
    "    for city_pref, stat_info in best_stations.items():\n",
    "        for st in stat_info['stations']:\n",
    "            if search in st['ekidata_line_ids']:\n",
    "                return city_pref, st\n",
    "    print(f'Something wrong happened with {line}---{id:02}')\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_routes = pd.DataFrame(columns=['from_city', 'to_city', 'type', 'from_station', 'to_station', 'distance', 'cost', 'route_id', 'enabled'])\n",
    "df_routes_verbose = pd.DataFrame(columns=['from_city', \n",
    "                                          'from_region_id', \n",
    "                                          'from_region_name', \n",
    "                                          'to_city', \n",
    "                                          'to_region_id', \n",
    "                                          'to_region_name', \n",
    "                                          'type', \n",
    "                                          'from_station', \n",
    "                                          'to_station', \n",
    "                                          'duration', \n",
    "                                          'distance', \n",
    "                                          'cost', \n",
    "                                          'route_id', \n",
    "                                          'route_name', \n",
    "                                          'enabled'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "for k, ls in recorded_line_stations.items():\n",
    "    if len(ls) == 1:\n",
    "        print(f\"line {k} is not processed\")\n",
    "        continue\n",
    "    for i in range(1, len(ls)):\n",
    "        from_city, from_info = find_st_on_lineid(k, ls[i - 1])\n",
    "        to_city, to_info = find_st_on_lineid(k, ls[i])\n",
    "        rows.append({\n",
    "            'from_city': from_city[:-5], \n",
    "            'from_region_id': int(from_city[-2:]) + 200, \n",
    "            'from_region_name': prefecture_dict[from_city[-2:]], \n",
    "            'to_city': to_city[:-5], \n",
    "            'to_region_id': int(to_city[-2:]) + 200, \n",
    "            'to_region_name': prefecture_dict[to_city[-2:]], \n",
    "            'type': 'train', \n",
    "            'from_station': from_info['name_romaji'], \n",
    "            'to_station': to_info['name_romaji'], \n",
    "            'duration': None,  # No available information\n",
    "            'distance': None,  # No available information \n",
    "            'cost': None,  # No available information\n",
    "            'route_id': f\"JPRail {k}\", \n",
    "            'route_name': find_line(str(k)), \n",
    "            'enabled': True\n",
    "        })\n",
    "        # Reverse edge\n",
    "        rows.append({\n",
    "            'to_city': from_city[:-5], \n",
    "            'to_region_id': int(from_city[-2:]) + 200, \n",
    "            'to_region_name': prefecture_dict[from_city[-2:]], \n",
    "            'from_city': to_city[:-5], \n",
    "            'from_region_id': int(to_city[-2:]) + 200, \n",
    "            'from_region_name': prefecture_dict[to_city[-2:]], \n",
    "            'type': 'train', \n",
    "            'to_station': from_info['name_romaji'], \n",
    "            'from_station': to_info['name_romaji'], \n",
    "            'duration': None,  # No available information\n",
    "            'distance': None,  # No available information \n",
    "            'cost': None,  # No available information\n",
    "            'route_id': f\"JPRail {k}\", \n",
    "            'route_name': find_line(str(k)), \n",
    "            'enabled': True\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routes_verbose = pd.concat([df_routes_verbose, pd.DataFrame(rows)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|    | from_city   |   from_region_id | from_region_name   | to_city   |   to_region_id | to_region_name   | type   | from_station   | to_station   | duration   | distance   | cost   | route_id    | route_name   | enabled   |\n",
      "|---:|:------------|-----------------:|:-------------------|:----------|---------------:|:-----------------|:-------|:---------------|:-------------|:-----------|:-----------|:-------|:------------|:-------------|:----------|\n",
      "|  0 | Tokyo       |              213 | Tokyo              | Tokyo     |            213 | Tokyo            | train  | Tokyo          | Ueno         |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n",
      "|  1 | Tokyo       |              213 | Tokyo              | Tokyo     |            213 | Tokyo            | train  | Ueno           | Tokyo        |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n",
      "|  2 | Tokyo       |              213 | Tokyo              | Saitama   |            211 | Saitama          | train  | Ueno           | Ōmiya        |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n",
      "|  3 | Saitama     |              211 | Saitama            | Tokyo     |            213 | Tokyo            | train  | Ōmiya          | Ueno         |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n",
      "|  4 | Saitama     |              211 | Saitama            | Kumagaya  |            211 | Saitama          | train  | Ōmiya          | Kumagaya     |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n",
      "|  5 | Kumagaya    |              211 | Saitama            | Saitama   |            211 | Saitama          | train  | Kumagaya       | Ōmiya        |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n",
      "|  6 | Kumagaya    |              211 | Saitama            | Takasaki  |            210 | Gunma            | train  | Kumagaya       | Takasaki     |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n",
      "|  7 | Takasaki    |              210 | Gunma              | Kumagaya  |            211 | Saitama          | train  | Takasaki       | Kumagaya     |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n",
      "|  8 | Takasaki    |              210 | Gunma              | Karuizawa |            220 | Nagano           | train  | Takasaki       | Karuizawa    |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n",
      "|  9 | Karuizawa   |              220 | Nagano             | Takasaki  |            210 | Gunma            | train  | Karuizawa      | Takasaki     |            |            |        | JPRail 1009 | 北陸新幹線   | True      |\n"
     ]
    }
   ],
   "source": [
    "print(df_routes_verbose.head(10).to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_routes_verbose.to_csv('processed_routes_big.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('processed_routes_big.csv')\n",
    "df[['from_city', 'from_region_name', 'to_city', 'to_region_name']] = df[['from_city', 'from_region_name', 'to_city', 'to_region_name']].apply(lambda x: x.str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('processed_routes_big.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total null rows (excluding duration, distance, and cost): 0\n"
     ]
    }
   ],
   "source": [
    "# Exclude specific columns from null check\n",
    "subset_cols = [col for col in df.columns if col not in ['duration', 'distance', 'cost']]\n",
    "\n",
    "# Count null rows in the subset\n",
    "null_count = df[subset_cols].isnull().sum()\n",
    "\n",
    "# Print the total number of null rows\n",
    "print(f\"Total null rows (excluding duration, distance, and cost): {null_count.sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "airportsF = open('Useful/processed_airports.json')\n",
    "airports = json.load(airportsF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "prefF = open('Useful/prefectures.json')\n",
    "prefs = json.load(prefF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for ap in airports:\n",
    "    ap['city'] = ap['city'].lower()\n",
    "    ap['region_id'] = int(\"2\" + ap['prefecture'])\n",
    "    ap['prefecture'] = prefs[int(ap['prefecture']) - 1]['prefecture_romaji'].lower()\n",
    "    ap['prefecture'] = ap['prefecture'].split(' ')[0]\n",
    "    ap['region_name'] = ap.pop('prefecture')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"Useful/processed_airports.json\", \"w\", encoding=\"utf-8\") as of:\n",
    "    json.dump(airports, of, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ō'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str('Ō').lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      from_city  from_region_id from_region_name    to_city  to_region_id  \\\n",
      "3044      osaka             227            osaka  amagasaki           228   \n",
      "3045  amagasaki             228            hyōgo      osaka           227   \n",
      "3046  amagasaki             228            hyōgo  amagasaki           228   \n",
      "3047  amagasaki             228            hyōgo  amagasaki           228   \n",
      "3048  amagasaki             228            hyōgo  amagasaki           228   \n",
      "...         ...             ...              ...        ...           ...   \n",
      "4551      saiki             244             ōita      saiki           244   \n",
      "4552      saiki             244             ōita      saiki           244   \n",
      "4553      saiki             244             ōita      saiki           244   \n",
      "4554      saiki             244             ōita    nobeoka           245   \n",
      "4555    nobeoka             245         miyazaki      saiki           244   \n",
      "\n",
      "     to_region_name   type           from_station             to_station  \\\n",
      "3044          hyōgo  train  Osaka-Umeda  (Hankyu)              Amagasaki   \n",
      "3045          osaka  train              Amagasaki  Osaka-Umeda  (Hankyu)   \n",
      "3046          hyōgo  train              Amagasaki             Tsukaguchi   \n",
      "3047          hyōgo  train             Tsukaguchi              Amagasaki   \n",
      "3048          hyōgo  train             Tsukaguchi                Inadera   \n",
      "...             ...    ...                    ...                    ...   \n",
      "4551           ōita  train                Naokawa                  Naomi   \n",
      "4552           ōita  train                Naokawa               Shigeoka   \n",
      "4553           ōita  train               Shigeoka                Naokawa   \n",
      "4554       miyazaki  train               Shigeoka               Ichitana   \n",
      "4555           ōita  train               Ichitana               Shigeoka   \n",
      "\n",
      "      duration  distance  cost      route_id        route_name  enabled  \n",
      "3044       NaN       NaN   NaN  JPRail 11629              福知山線     True  \n",
      "3045       NaN       NaN   NaN  JPRail 11629              福知山線     True  \n",
      "3046       NaN       NaN   NaN  JPRail 11629              福知山線     True  \n",
      "3047       NaN       NaN   NaN  JPRail 11629              福知山線     True  \n",
      "3048       NaN       NaN   NaN  JPRail 11629              福知山線     True  \n",
      "...        ...       ...   ...           ...               ...      ...  \n",
      "4551       NaN       NaN   NaN  JPRail 11907  JR日豊本線(佐伯～鹿児島中央)     True  \n",
      "4552       NaN       NaN   NaN  JPRail 11907  JR日豊本線(佐伯～鹿児島中央)     True  \n",
      "4553       NaN       NaN   NaN  JPRail 11907  JR日豊本線(佐伯～鹿児島中央)     True  \n",
      "4554       NaN       NaN   NaN  JPRail 11907  JR日豊本線(佐伯～鹿児島中央)     True  \n",
      "4555       NaN       NaN   NaN  JPRail 11907  JR日豊本線(佐伯～鹿児島中央)     True  \n",
      "\n",
      "[368 rows x 15 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find rows with \"ō\" in either column\n",
    "filtered_df = df[(df['from_region_name'].str.contains('ō')) | (df['to_region_name'].str.contains('ō'))]\n",
    "\n",
    "print(filtered_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
